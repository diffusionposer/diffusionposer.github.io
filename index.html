<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Diffusion models for...">
  <meta name="keywords" content="Diffusion, Motion Generation, Inertial Motion Capture">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion</h1>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="./static/videos/teaser.mp4"-->
<!--                type="video/mp4">-->
<!--      </video>-->

      <img id="teaser" src="./static/images/differentConfig_v2.jpg"
       alt="Teaser figure."/>
      <h2 class="subtitle has-text-centered">
        Reconstructions of the same sequence with PIP <a href="https://xinyu-yi.github.io/PIP/">[Yi et al. 2022]</a>  using 6 sensors and OURS using 6, 4, 3 and 2 IMU sensors. 
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">

          <p>
				Motion capture from a limited number of body-worn sensors, such as inertial measurement units (IMUs) and pressure insoles, has important applications in health, human performance, and entertainment. 
				Recent work has focused on accurately reconstructing whole-body motion from a specific sensor configuration using six IMUs. 
				While a common goal across applications is to use the minimal number of sensors to achieve required accuracy, the optimal arrangement of the sensors might differ from application to application.
          </p>
          <p>
				We propose a single diffusion model, DiffusionPoser, which reconstructs human motion in real-time from arbitrary sensor configurations including IMUs and pressure insoles. 
				Unlike existing methods, our model grants users the flexibility to determine the number and arrangement of sensors tailored to the specific activity of interest, without the need for retraining. 
				A novel autoregressive inferencing scheme ensures real-time motion reconstruction that closely aligns with measured sensor signals. 
				The generative nature of DiffusionPoser ensures realistic behavior, even for degrees-of-freedom not directly measured. 


          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
	
	
	 <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Live Demo: Diverse motion and locomotion with six IMU sensors</h2>
		<div class="content has-text-justified">
          <p>
				We construct diverse motion while instrumenting the pelvis, head, wrists and shanks. 
				This is the configuration that has been used in a series of prior work (<a href="https://xinyu-yi.github.io/TransPose/">[Yi et al. 2021]</a>, <a href="https://xinyu-yi.github.io/PIP/">[Yi et al. 2022]</a>,<a href="https://github.com/jyf588/transformer-inertial-poser">[Jiang et al. 2022]</a>) . 
				In our paper we show quantitatively that our reconstructions are as good as previous systems for this specific configuration.
				For this video we replace our stick-figure reconstruction with a SMPL mesh  and remove the delay, in order to appreciate details better. The reconstruction is still done with the live algorithm - but just after data collection. 
				In the following videos we show the reconstruction on the monitor and real motion together. 
          </p>
        </div>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/AP_UTbtnFlc?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
	
	
	
	
	
	
	 <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Live Demo: Diverse motion and locomotion with five IMU sensors</h2>
		<div class="content has-text-justified">
          <p>
				We remove an IMU and slightly change the configuration that now consists of five IMUs attached to the feet, pelvis, left wrist and right thigh. 
				Such configuration matches convenient locations to attach devices for daily life activity monitoring (shoes, belt, watch, smartphone).
				We reconstruct a similar set of diverse motions. Note that uninstrumented segments are reconstructed realistically (f.e. right arm swing during walking) but that specific motions might not be captured.
          </p>
        </div>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/_5djAUxrD9k?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
	
		 <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Live Demo: Diverse motion and locomotion with four IMU sensors</h2>
		<div class="content has-text-justified">
          <p>
				We remove another sensor and now instrument the left wrist, right thigh and the feet and reconstruct a similar sequence of diverse motions. 
				This configuration mimics a realistic real-life setup with instrumented shoes, a watch and a smartphone.
          </p>
        </div>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/CzvKaH2YcWg?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
	
	
	
		 <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Live Demo: Diverse motion and locomotion with six IMU sensors, but with live visualization.</h2>
		          <p>
				This is a repeat of the first video, but with the live reconstruction on the monitor and human motion captured together. 
          </p>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/FAxBZNTzfbs?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

	
	<!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Live Demo: Clinically relevant gait deviations captured with 3 sensors (foot L/R and pelvis)</h2>
		
		 <div class="content has-text-justified">
          <p>
				We remove more sensors and now have a setup with 3 IMUs. Such setups are useful for monitoring over long periods of time.
				Clinical studies that aim to monitor patients and track rehabilation would benefit from continuous gait analysis during daily life. 
				Here we show that 3 sensors suffice to capture some typical gait deviations in different patient populations
          </p>
		  <p>
				Toe-in and toe-out gait are two gait deviations that can reduce knee load in patients with knee pain (e.g. knee osteoarthritis patients).  <a href="https://pubmed.ncbi.nlm.nih.gov/29174534/">[Uhlrich et al. 2018]</a> 
          </p>
		  <p>
				Scissor gait is a gait deviation/compensation observed in patients with hip adductor spasticity (e.g. cerebral palsy patients).
          </p>
		  <p>
				Patients with a weak hip flexor on one side compensate by exorotating the hip joint to shift the workload to the hip adductor. A weak hip flexor on one side is observed in patients with nerve damage or hip osteoarthritis patients.
          </p>
        </div>
		
		
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/-cBe_UY8YsM?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Live Demo: Tennis</h2>
		
				 <div class="content has-text-justified">
          <p>
				Finally we go back to our setup with six sensors and reconstruct dynamic motion outdoors. We record a tennis player, who is playing against the wall. 
          </p>
        </div>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/Ht29y86JAPU?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">



    <!-- two char. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Signal drop is completed by our generative model. </h2>
		
	    <div class="content has-text-justified">
          <p>
			Our generative model can complete motion realistically if signals from sensors become unreliable or are lost. (f.e. lost connection or package losses).
			Here we show reconstructions of motions where at a certain point in time we drop the signal form all sensors for a couple of seconds. 
			Our generative model completes the motion.
			As soon as signals are back a natural transition is performed to match the underlying motion. 
			Regressive models such as PIP do not have this capacity to complete motion realistically.
          </p>
        </div>
		<div class="content has-text-centered">
			<video id="two-char"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
				<source src="./static/videos/signalDrop_full.mp4"
                    type="video/mp4">
			</video>
        </div>
		
		
		<div class="content has-text-justified">
          <p>
			Here are some more examples of generative motion completion when signal is lost using DiffusionPoser.
          </p>
        </div>
		<div class="content has-text-centered">
			<video id="two-char"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
				<source src="./static/videos/signalDrop_s2_acting2_1.mp4"
                    type="video/mp4">
			</video>
        </div>
		
		

		<div class="content has-text-centered">
			<video id="two-char"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
				<source src="./static/videos/recon_DiffusionPoser_s3_freestyle3_0.mp4"
                    type="video/mp4">
			</video>
        </div>
		

		<div class="content has-text-centered">
			<video id="two-char"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
				<source src="./static/videos/recon_DiffusionPoser_s3_freestyle3_1.mp4"
                    type="video/mp4">
			</video>
        </div>
		</div>

      </div>
	  
	  
	  
	  
    </div>
    <!--/ two char. -->

    

  </div>
</section>






<section class="section">
  <div class="container is-max-desktop">

	  


    <!-- two char. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">DiffusionPoser for OpenSim</h2>
		
		 <div class="content has-text-justified">
          <p>
				A video that summarizes results for DiffusionPoser for OpenSim.
				It includes more live demos and results with different configurations. 
				We also compare to a purely regressive model.
          </p>
        </div>
		
		        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/JoRSlv9YR_A?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
		
		    </div>
	  
	  
	  
	  
    </div>
    <!--/ two char. -->

    

  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
